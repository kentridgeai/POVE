{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f280a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-04T13:43:26.761Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from gplearn_memetic.simplification import replace_C_with_indices, replace_C_indices_with_values\n",
    "from gplearn_memetic._program import BAD_PRED_VALUE\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from pmlb import fetch_data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for random_state in [11284, 11964, 15795, 21575, 22118, 23654, 29802,  5390,  6265, 860]:# SRBench train_test_split random seed\n",
    "\n",
    "    BATCH_SIZE = 1000000\n",
    "    \n",
    "    dataset_list = ['1027_ESL',\n",
    "     '1029_LEV',\n",
    "     '1030_ERA',\n",
    "     '1096_FacultySalaries',\n",
    "     '192_vineyard',\n",
    "     '210_cloud',\n",
    "     '228_elusage',\n",
    "     '230_machine_cpu',\n",
    "     '485_analcatdata_vehicle',\n",
    "     '519_vinnie',\n",
    "     '522_pm10',\n",
    "     '523_analcatdata_neavote',\n",
    "     '529_pollen',\n",
    "     '547_no2',\n",
    "     '556_analcatdata_apnea2',\n",
    "     '557_analcatdata_apnea1',\n",
    "     '561_cpu',\n",
    "     '579_fri_c0_250_5',\n",
    "     '594_fri_c2_100_5',\n",
    "     '596_fri_c2_250_5',\n",
    "     '597_fri_c2_500_5',\n",
    "     '599_fri_c2_1000_5',\n",
    "     '609_fri_c0_1000_5',\n",
    "     '612_fri_c1_1000_5',\n",
    "     '628_fri_c3_1000_5',\n",
    "     '663_rabe_266',\n",
    "     '665_sleuth_case2002',\n",
    "     '678_visualizing_environmental',\n",
    "     '687_sleuth_ex1605',\n",
    "     '690_visualizing_galaxy',\n",
    "     '706_sleuth_case1202',\n",
    "     '712_chscase_geyser1',]\n",
    "    \n",
    "    # Load dataset once and preprocess\n",
    "    for dataset_name in dataset_list:\n",
    "        X, y = fetch_data(dataset_name, return_X_y=True, local_cache_dir='./pmlb_data/')\n",
    "        X, X_test, y, y_test = train_test_split(\n",
    "            X, y, train_size=0.75, test_size=0.25, random_state=random_state\n",
    "        )\n",
    "        scaler_X = StandardScaler()\n",
    "        X = scaler_X.fit_transform(X)\n",
    "        X_test = scaler_X.transform(X_test)\n",
    "    \n",
    "        scaler_y = StandardScaler()\n",
    "        y = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "        y_test = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "        def cost(C, X, y, executable_expr_skeleton): \n",
    "            y_pred = eval(executable_expr_skeleton)\n",
    "            if isinstance(y_pred, (float,int)):\n",
    "                y_pred = np.repeat(y_pred, X.shape[0])\n",
    "            if not np.all(np.isfinite(y_pred)):\n",
    "                y_pred = np.repeat(BAD_PRED_VALUE, X.shape[0])\n",
    "            return mean_squared_error(y, y_pred)\n",
    "    \n",
    "        # Function to process each expression (to be used with multiprocessing)\n",
    "        def process_expression(expr_skeleton):\n",
    "            executable_expr_skeleton_C, C_count = replace_C_with_indices(expr_skeleton)\n",
    "            executable_expr_skeleton = re.sub(r'X(\\d+)', r'X[:,\\1]', executable_expr_skeleton_C)\n",
    "    \n",
    "            if C_count:  # If constants need optimization\n",
    "                np.random.seed(42)\n",
    "                C = (2 * np.random.rand(C_count) - 1)\n",
    "                try:\n",
    "                    res = minimize(cost, x0=C, args=(X, y, executable_expr_skeleton), method=\"BFGS\")\n",
    "                    C = res.x\n",
    "                    nit = res.nit\n",
    "                except:\n",
    "                    nit = 0\n",
    "                executable_expr_final = replace_C_indices_with_values(executable_expr_skeleton, C)\n",
    "                optimized_program = replace_C_indices_with_values(executable_expr_skeleton_C, C)\n",
    "            else:\n",
    "                C = None\n",
    "                nit = None\n",
    "                executable_expr_final = executable_expr_skeleton\n",
    "                optimized_program = executable_expr_skeleton_C\n",
    "    \n",
    "            try:\n",
    "                answer = eval(executable_expr_final)\n",
    "                if isinstance(answer, (float,int)):\n",
    "                    answer = np.repeat(answer, X.shape[0])\n",
    "                if not np.all(np.isfinite(answer)):\n",
    "                    answer = np.repeat(BAD_PRED_VALUE, X.shape[0])\n",
    "        \n",
    "                mse = mean_squared_error(y, answer)\n",
    "                rmse = np.sqrt(mse)\n",
    "                mae = mean_absolute_error(y, answer)\n",
    "                r2 = r2_score(y, answer)\n",
    "                result_train = [mse, rmse, mae, r2]\n",
    "            except:\n",
    "                result_train = [None] * 4\n",
    "            \n",
    "            try:        \n",
    "                answer_test = eval(executable_expr_final.replace('y','y_test').replace('X','X_test'))\n",
    "                if isinstance(answer_test, (float,int)):\n",
    "                    answer_test = np.repeat(answer_test, X_test.shape[0])\n",
    "                if not np.all(np.isfinite(answer_test)):\n",
    "                    answer_test = np.repeat(BAD_PRED_VALUE, X_test.shape[0])\n",
    "        \n",
    "                mse_test = mean_squared_error(y_test, answer_test)\n",
    "                rmse_test = np.sqrt(mse)\n",
    "                mae_test = mean_absolute_error(y_test, answer_test)\n",
    "                r2_test = r2_score(y_test, answer_test)\n",
    "                result_test = [mse_test, rmse_test, mae_test, r2_test]\n",
    "            except:\n",
    "                result_test = [None] * 4\n",
    "                \n",
    "            return [expr_skeleton, C, optimized_program, nit] + result_train + result_test\n",
    "    \n",
    "        for expr_length in range(1, 12):\n",
    "            new_csv_filename = f\"optimized_data/{dataset_name}_seed{random_state}_len{expr_length}.csv\"\n",
    "            new_feather_filename = f\"optimized_data/{dataset_name}_seed{random_state}_len{expr_length}.feather\"\n",
    "            file_path = f\"skeleton_data/len{expr_length}_features{X.shape[1]}.feather\"\n",
    "    \n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"skeleton_data file for {expr_length=}, features={X.shape[1]} does not exist\")\n",
    "                continue\n",
    "    \n",
    "            if os.path.exists(new_feather_filename):\n",
    "                print(f\"{new_feather_filename} done\")\n",
    "                continue\n",
    "    \n",
    "            df = pd.read_feather(file_path)\n",
    "            expression_list = df[\"Expression\"].tolist()\n",
    "    \n",
    "            # Check if the CSV file already exists to resume processing\n",
    "            processed_expressions = set()\n",
    "            if os.path.exists(new_csv_filename):\n",
    "                existing_df = pd.read_csv(new_csv_filename, usecols=[\"Expression Skeleton\"])\n",
    "                processed_expressions = set(existing_df[\"Expression Skeleton\"])\n",
    "                print(f\"Resuming {new_csv_filename}, skipping {len(processed_expressions)} already processed expressions.\")\n",
    "    \n",
    "            # Filter out expressions that are already done\n",
    "            expressions_to_process = [expr for expr in expression_list if expr not in processed_expressions]\n",
    "    \n",
    "            if not expressions_to_process:\n",
    "                print(f\"All expressions are already processed for length {expr_length}. Skipping...\")\n",
    "                continue\n",
    "    \n",
    "            # Process in batches of BATCH_SIZE\n",
    "            for i in range(0, len(expressions_to_process), BATCH_SIZE):\n",
    "                batch = expressions_to_process[i:i + BATCH_SIZE]\n",
    "                print(f\"Processing batch {i // BATCH_SIZE + 1} of {len(expressions_to_process) // BATCH_SIZE + 1} for length {expr_length}\")\n",
    "    \n",
    "                results_data = []\n",
    "                with multiprocessing.Pool(processes=max(1, os.cpu_count()-1)) as pool:\n",
    "                    for result in tqdm(\n",
    "                        pool.imap_unordered(process_expression, batch),\n",
    "                        total=len(batch),\n",
    "                        desc=f\"Batch {i // BATCH_SIZE + 1} processing\",\n",
    "                        unit=\"expr\"\n",
    "                    ):\n",
    "                        if result:\n",
    "                            results_data.append(result)\n",
    "    \n",
    "                # Save after processing each batch\n",
    "                if results_data:\n",
    "                    results_data_df = pd.DataFrame(\n",
    "                        results_data,\n",
    "                        columns=[\n",
    "                            \"Expression Skeleton\", \"C\", \"Full Expression\", \"Optimization Iterations\",\n",
    "                            \"MSE Train Fitness\", \"RMSE Train Fitness\", \"MAE Train Fitness\", \"R2 Train Fitness\",\n",
    "                            \"MSE Test\", \"RMSE Test\", \"MAE Test\", \"R2 Test\",\n",
    "                        ]\n",
    "                    )\n",
    "                    # Append to CSV\n",
    "                    results_data_df.to_csv(new_csv_filename, mode='a', header=not os.path.exists(new_csv_filename), index=False)\n",
    "                    print(f\"Saved batch {i // BATCH_SIZE + 1} results to {new_csv_filename}\")\n",
    "    \n",
    "            # Load CSV file\n",
    "            df = pd.read_csv(new_csv_filename)\n",
    "            df.drop_duplicates(subset=['Expression Skeleton'], inplace=True)\n",
    "            df.sort_values(by=['Expression Skeleton'], inplace=True)\n",
    "            # Save back to CSV (cleaned version)\n",
    "            df.to_csv(new_csv_filename, index=False)\n",
    "            df.to_feather(new_feather_filename)\n",
    "            print(f\"Cleaned and converted {new_csv_filename} → {new_feather_filename}\")\n",
    "    \n",
    "            print(f\"Finished processing all batches for length {expr_length}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": "24",
    "lenType": "24",
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
